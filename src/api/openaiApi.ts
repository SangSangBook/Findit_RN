import { OPENAI_API_KEY } from '@env';
import OpenAI from 'openai';

if (!OPENAI_API_KEY) {
  throw new Error('OpenAI API key is not set. Please check your .env file.');
}

const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
});

/**
 * OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
 * @param text ìš”ì•½í•  í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
 * @returns ìš”ì•½ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ëŠ” Promise ê°ì²´ì…ë‹ˆë‹¤.
 */
export const getInfoFromTextWithOpenAI = async (text: string | null): Promise<string> => {
  if (!text) {
    return 'ì •ë³´ë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.';
  }
  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { 
          role: 'system', 
          content: `ë‹¹ì‹ ì€ ì´ë¯¸ì§€ ë¶„ì„ ë° Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ëª¨ë“  ì‘ë‹µì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë©°, ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
1. **ì£¼ìš” ì •ë³´ ìš”ì•½** (2-3ë¬¸ì¥)
2. **í•µì‹¬ ë¶„ì„** (ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ê°„ë‹¨íˆ)
3. **ì¶”ê°€ ì •ë³´** (í•„ìš”í•œ ê²½ìš°ì—ë§Œ)

ì˜ˆì‹œ 1 (ì§ˆë¬¸ í¬í•¨):
ë¶„ì„ ê²°ê³¼: "[í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼] íšŒì˜ë¡: í”„ë¡œì íŠ¸ X ì§„í–‰ ìƒí™© ë³´ê³ 
[ê°ì§€ëœ ë¬¼ì²´] - ë…¸íŠ¸ë¶ - ì‚¬ëŒ - ì±…ìƒ
[ì´ë¯¸ì§€ ë¼ë²¨] - íšŒì˜ - ì‚¬ë¬´ì‹¤ - ë¹„ì¦ˆë‹ˆìŠ¤
[ì–¼êµ´ ê°ì§€ ê²°ê³¼] ì–¼êµ´ 1: - ê¸°ì¨: VERY_LIKELY
ì§ˆë¬¸: ì´ íšŒì˜ì˜ ë¶„ìœ„ê¸°ëŠ” ì–´ë– í•œê°€ìš”?"

ë‹¹ì‹ ì˜ ì‘ë‹µ: "## íšŒì˜ ë¶„ìœ„ê¸° ë¶„ì„

ì´ íšŒì˜ëŠ” í”„ë¡œì íŠ¸ Xì˜ ì§„í–‰ ìƒí™©ì„ ë³´ê³ í•˜ëŠ” ìë¦¬ë¡œ, ì „ë°˜ì ìœ¼ë¡œ ê¸ì •ì ì´ê³  í™œê¸°ì°¬ ë¶„ìœ„ê¸°ì…ë‹ˆë‹¤.

### í•µì‹¬ ë¶„ì„
* ğŸ˜Š ì°¸ì„ìë“¤ì˜ ê¸°ì¨ í‘œì •ì´ ë‘ë“œëŸ¬ì§
* ğŸ’» ë…¸íŠ¸ë¶ì„ í™œìš©í•œ ì§„í–‰ ìƒí™© ë³´ê³ 
* ğŸ¢ ì‚¬ë¬´ì‹¤ í™˜ê²½ì—ì„œì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¯¸íŒ…

### ì¶”ê°€ ì •ë³´
* íšŒì˜ì‹¤ì˜ ë°ì€ ì¡°ëª…ê³¼ ê¹”ë”í•œ í™˜ê²½ì´ ê¸ì •ì ì¸ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±"

ì˜ˆì‹œ 2 (ì§ˆë¬¸ ì—†ìŒ):
ë¶„ì„ ê²°ê³¼: "[í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼] ì œí’ˆëª…: ìŠ¤ë§ˆíŠ¸ ì›Œì¹˜ Pro
[ê°ì§€ëœ ë¬¼ì²´] - ìŠ¤ë§ˆíŠ¸ì›Œì¹˜ - ì†ëª©
[ì´ë¯¸ì§€ ë¼ë²¨] - ì „ìì œí’ˆ - ì›¨ì–´ëŸ¬ë¸”
[ë¡œê³  ê°ì§€ ê²°ê³¼] - Apple
[ê´€ë ¨ ì£¼ì œ] - ê±´ê°• ëª¨ë‹ˆí„°ë§"

ë‹¹ì‹ ì˜ ì‘ë‹µ: "## ì œí’ˆ ë¶„ì„

Appleì˜ ìŠ¤ë§ˆíŠ¸ ì›Œì¹˜ ProëŠ” ê±´ê°• ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì„ ê°•ì¡°í•˜ëŠ” í”„ë¦¬ë¯¸ì—„ ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°ì…ë‹ˆë‹¤.

### í•µì‹¬ ë¶„ì„
* âŒš ì†ëª©ì— ì°©ìš©ëœ ìŠ¤ë§ˆíŠ¸ì›Œì¹˜
* ğŸ Apple ë¸Œëœë“œ ì œí’ˆ
* â¤ï¸ ê±´ê°• ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ ê°•ì¡°

### ì¶”ê°€ ì •ë³´
* ê²€ì€ìƒ‰ê³¼ í°ìƒ‰ì˜ ëŒ€ë¹„ê°€ ê°•í•œ ì„¸ë ¨ëœ ë””ìì¸
* ì›¨ì–´ëŸ¬ë¸” ê¸°ìˆ ê³¼ ê±´ê°• ê´€ë¦¬ì˜ ê²°í•©ì„ ê°•ì¡°í•˜ëŠ” ë§ˆì¼€íŒ… ì´ë¯¸ì§€"

ì œê³µëœ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ê°„ê²°í•œ ì‘ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”.`
        },
        { role: 'user', content: text },
      ],
      max_tokens: 500,
      temperature: 0.7,
    });

    const information = completion.choices[0]?.message?.content;
    if (!information || information.trim() === '') {
      throw new Error('OpenAI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.');
    }
    return information;

  } catch (error) {
    console.error('ì •ë³´ ì¶”ì¶œì„ ìœ„í•´ OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜:', error);
    if (error instanceof OpenAI.APIError) {
        return `OpenAI API ì˜¤ë¥˜: ${error.status} ${error.name} ${error.message}`;
    }
    return 'OpenAI ì‘ë‹µì´ ì—†ê±°ë‚˜, ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ë¡œ ì¸í•´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.';
  }
};

export interface TaskSuggestion {
  task: string;
  priority: 'ì¤‘ìš”' | 'ë³´í†µ' | 'ë‚®ìŒ';
}

/**
 * OCR í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ë“¤ì„ ì œì•ˆí•©ë‹ˆë‹¤.
 * @param ocrText OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
 * @returns ì œì•ˆëœ ì‘ì—… ëª©ë¡
 */
export const suggestTasksFromOcr = async (ocrText: string | null): Promise<TaskSuggestion[]> => {
  try {
    if (!ocrText) {
      return [];
    }

    const prompt = `
      ë‹¤ìŒì€ ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ë“¤ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
      ìµœì†Œ 3ê°œ ì´ìƒì˜ ì‘ì—…ì„ ì œì•ˆí•´ì£¼ì„¸ìš”. ê°ê° ë‹¤ë¥¸ ìš°ì„ ìˆœìœ„(high, medium, low)ë¥¼ ê°€ì§„ ì‘ì—…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
      
      í…ìŠ¤íŠ¸:
      ${ocrText}
    `;

    // íƒ€ì„ì•„ì›ƒ ì„¤ì •
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), 30000);

    const response = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: `ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ì„ ì œì•ˆí•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
2. ì‘ì—… ì œëª©ì€ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
3. ì‘ì—… ì„¤ëª…ì€ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
4. ë°˜ë“œì‹œ 3ê°œ ì´ìƒì˜ ì‘ì—…ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
5. ê° ì‘ì—…ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
   [ìš°ì„ ìˆœìœ„] ì‘ì—… ì œëª©
   - ì„¤ëª…: ì‘ì—…ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…

6. ìš°ì„ ìˆœìœ„ëŠ” ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”:
   - [ì¤‘ìš”]: ì¦‰ì‹œ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ì¤‘ìš”í•œ ì‘ì—… (ìµœì†Œ 1ê°œ)
   - [ë³´í†µ]: ê³§ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ì‘ì—… (ìµœì†Œ 1ê°œ)
   - [ë‚®ìŒ]: ì—¬ìœ ê°€ ìˆì„ ë•Œ ì²˜ë¦¬í•´ë„ ë˜ëŠ” ì‘ì—… (ìµœì†Œ 1ê°œ)`
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.7,
      // signal ì¶”ê°€í•´ì„œ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
    }, {
      signal: controller.signal
    });

    clearTimeout(timeoutId);

    const content = response.choices[0]?.message?.content;
    if (!content) {
      return [];
    }

    // í…ìŠ¤íŠ¸ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ TaskSuggestion ë°°ì—´ë¡œ ë³€í™˜
    const lines = content.split('\n');
    const suggestions: TaskSuggestion[] = [];
    let currentTask: Partial<TaskSuggestion> = {};

    for (const line of lines) {
      const trimmedLine = line.trim();
      if (!trimmedLine) continue;

      // ìš°ì„ ìˆœìœ„ì™€ ì œëª©ì´ ìˆëŠ” ë¼ì¸ ì²˜ë¦¬
      if (trimmedLine.startsWith('[') && trimmedLine.includes(']')) {
        if (currentTask.task && currentTask.priority) {
          suggestions.push(currentTask as TaskSuggestion);
        }
        
        const priorityMatch = trimmedLine.match(/\[(.*?)\]/);
        const priority = priorityMatch ? priorityMatch[1] : '';
        const title = trimmedLine.split(']')[1].trim();
        
        currentTask = {
          task: title,
          priority: priority === 'ì¤‘ìš”' ? 'ì¤‘ìš”' : 
                   priority === 'ë³´í†µ' ? 'ë³´í†µ' : 
                   priority === 'ë‚®ìŒ' ? 'ë‚®ìŒ' : 'ë³´í†µ',
        };
      }
    }

    // ë§ˆì§€ë§‰ ì‘ì—… ì¶”ê°€
    if (currentTask.task && currentTask.priority) {
      suggestions.push(currentTask as TaskSuggestion);
    }

    return suggestions;
  } catch (error) {
    console.error('Task suggestion error:', error);
    
    // AbortError íŠ¹ë³„ ì²˜ë¦¬
    if (error instanceof Error && error.name === 'AbortError') {
      console.log('OpenAI API íƒ€ì„ì•„ì›ƒ ë°œìƒ');
    }
    
    return [];
  }
};

/**
 * ì„ íƒëœ ì‘ì—…ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
 * @param task ì„ íƒëœ ì‘ì—… ì •ë³´
 * @param ocrText ì›ë³¸ OCR í…ìŠ¤íŠ¸
 * @returns ì‘ì—…ì— ëŒ€í•œ ìƒì„¸ ì •ë³´
 */
export const getTaskDetails = async (
  task: TaskSuggestion,
  ocrText: string | null
): Promise<string> => {
  try {
    if (!ocrText) {
      return 'ì›ë³¸ í…ìŠ¤íŠ¸ê°€ ì—†ì–´ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
    }

    const prompt = `
      ë‹¤ìŒì€ ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì™€ ì„ íƒëœ ì‘ì—…ì…ë‹ˆë‹¤.
      ì´ ì‘ì—…ì— ëŒ€í•´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
      
      ì„ íƒëœ ì‘ì—…:
      - ì œëª©: ${task.task}
      - ìš°ì„ ìˆœìœ„: ${task.priority}
      
      ì›ë³¸ í…ìŠ¤íŠ¸:
      ${ocrText}

      ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í¬í•¨í•˜ì—¬ ë…¼ë¦¬ì •ì—°í•˜ê³  ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:
      1. ì´ ì‘ì—…ì´ ì™œ ì¤‘ìš”í•œì§€
      2. ì´ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ë‹¨ê³„
      3. ì´ ì‘ì—…ê³¼ ê´€ë ¨ëœ ì£¼ì˜ì‚¬í•­ì´ë‚˜ íŒ
    `;

    return await getInfoFromTextWithOpenAI(prompt);
  } catch (error) {
    console.error('Task details error:', error);
    return 'ì‘ì—… ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
  }
};
